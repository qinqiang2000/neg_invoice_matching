"""
è´Ÿæ•°å‘ç¥¨åŒ¹é…ç³»ç»Ÿ - æµ‹è¯•æ•°æ®ç”Ÿæˆå™¨
ä¼˜åŒ–ç‰ˆæœ¬ï¼šæ”¯æŒå‚æ•°æ§åˆ¶ã€æ¨¡å—åŒ–æ“ä½œå’Œå¹‚ç­‰æ€§è®¾è®¡

åˆ›å»ºæ—¥æœŸ: 2025-09-27
ä½œè€…: ç³»ç»Ÿ

ä¸»è¦åŠŸèƒ½:
- åˆ›å»ºæµ‹è¯•æ•°æ®åº“è¡¨ç»“æ„
- ç”Ÿæˆå¤§é‡è“ç¥¨è¡Œæµ‹è¯•æ•°æ®ï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰
- åˆ›å»ºæ•°æ®åº“ç´¢å¼•
- ç”Ÿæˆç¤ºä¾‹è´Ÿæ•°å‘ç¥¨
- æ‰¹æ¬¡ç®¡ç†å’Œæ•°æ®è¿½è¸ª
- æä¾›ç»Ÿè®¡åˆ†æåŠŸèƒ½

ä½¿ç”¨æ–¹å¼ç¤ºä¾‹:
    # å®Œæ•´è®¾ç½®ï¼ˆé¦–æ¬¡ä½¿ç”¨ï¼‰
    python test_data_generator.py --setup-db --generate-blue-lines --total-lines 1000000 --create-indexes

    # å¤§æ•°æ®é‡ç”Ÿæˆï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰
    python test_data_generator.py --generate-blue-lines --total-lines 10000000 --batch-id prod_001

    # æŸ¥çœ‹æ‰¹æ¬¡çŠ¶æ€
    python test_data_generator.py --list-batches

    # æ¸…ç†ç‰¹å®šæ‰¹æ¬¡
    python test_data_generator.py --clear-batch prod_001

    # ç”Ÿæˆæµ‹è¯•è´Ÿæ•°å‘ç¥¨
    python test_data_generator.py --generate-negatives --scenario mixed --count 500
"""

import sys
import os
import argparse
from datetime import datetime
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import psycopg2
from psycopg2.extras import execute_values
import random
import numpy as np
import time
from tqdm import tqdm
from typing import List, Dict, Optional
from decimal import Decimal

# å¯¼å…¥æ ¸å¿ƒæ¨¡å—çš„æ•°æ®æ¨¡å‹
from core.matching_engine import NegativeInvoice

# SQLå·¥å…·å‡½æ•°
def load_sql_file(filename: str) -> str:
    """
    åŠ è½½SQLæ–‡ä»¶å†…å®¹

    Args:
        filename: SQLæ–‡ä»¶åï¼Œç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•çš„sql/è·¯å¾„

    Returns:
        str: SQLæ–‡ä»¶å†…å®¹
    """
    sql_path = os.path.join(
        os.path.dirname(os.path.dirname(os.path.abspath(__file__))),
        'sql', filename
    )

    try:
        with open(sql_path, 'r', encoding='utf-8') as f:
            return f.read()
    except FileNotFoundError:
        raise FileNotFoundError(f"SQLæ–‡ä»¶æœªæ‰¾åˆ°: {sql_path}")
    except Exception as e:
        raise Exception(f"è¯»å–SQLæ–‡ä»¶å¤±è´¥ {sql_path}: {e}")

class TestDataGenerator:
    """
    æµ‹è¯•æ•°æ®ç”Ÿæˆå™¨
    å¯å¤ç”¨äºï¼š
    1. åˆå§‹åŒ–æµ‹è¯•æ•°æ®åº“
    2. ç”Ÿæˆæ€§èƒ½æµ‹è¯•æ•°æ®
    3. ç”Ÿæˆç‰¹å®šåœºæ™¯çš„æµ‹è¯•ç”¨ä¾‹
    """
    
    def __init__(self, db_config: Dict, config: Optional[Dict] = None, seed: Optional[int] = None):
        """
        åˆå§‹åŒ–æ•°æ®ç”Ÿæˆå™¨

        Args:
            db_config: æ•°æ®åº“é…ç½®
            config: æµ‹è¯•é…ç½®ï¼ˆå¯é€‰ï¼Œç”¨äºè¦†ç›–é»˜è®¤é…ç½®ï¼‰
            seed: éšæœºç§å­ï¼ˆå¯é€‰ï¼Œç”¨äºç”Ÿæˆå¯é‡å¤çš„æµ‹è¯•æ•°æ®ï¼‰
        """
        self.conn = psycopg2.connect(**db_config)
        self.cur = self.conn.cursor()

        # è®¾ç½®éšæœºç§å­ï¼ˆç”¨äºå¯é‡å¤æµ‹è¯•ï¼‰
        if seed is not None:
            random.seed(seed)
            np.random.seed(seed)
            self.seed = seed
            print(f"ğŸŒ± å·²è®¾ç½®éšæœºç§å­: {seed} (æ•°æ®å°†å®Œå…¨å¯é‡å¤)")
        else:
            self.seed = None

        # ä½¿ç”¨ä¼ å…¥çš„é…ç½®æˆ–é»˜è®¤é…ç½®
        if config:
            self.total_lines = config.get('total_lines', 10_000_000)
            self.batch_size = config.get('batch_size', 10000)
        else:
            self.total_lines = 10_000_000  # 1000ä¸‡æ¡
            self.batch_size = 10000  # æ‰¹é‡æ’å…¥å¤§å°

        # ä¸šåŠ¡åˆ†å¸ƒå‚æ•°
        self.tax_rates = [13, 6, 3, 0]
        self.tax_weights = [0.6, 0.25, 0.1, 0.05]

        # ä¹°å–æ–¹é…ç½®
        self._init_buyer_seller_config()
        
    def _init_buyer_seller_config(self):
        """
        åˆå§‹åŒ–ä¹°å–æ–¹é…ç½®ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
        å‡å°‘ç»„åˆæ•°é‡ï¼Œå¢åŠ æ•°æ®å¯†åº¦ï¼Œæé«˜åŒ¹é…ç‡
        """
        # ä¼˜åŒ–åçš„é…ç½®ï¼šæ›´å°‘çš„ä¹°å–æ–¹ï¼Œæ›´é«˜çš„å¯†åº¦
        self.hot_buyers = list(range(1, 11))      # Top 10ä¹°æ–¹ (40%æ¦‚ç‡)
        self.hot_sellers = list(range(1, 11))     # Top 10å–æ–¹
        self.regular_buyers = list(range(11, 51))  # Top 50ä¹°æ–¹ (40%æ¦‚ç‡ï¼ŒåŸæ¥æ˜¯100)
        self.regular_sellers = list(range(11, 51)) # Top 50å–æ–¹
        self.all_buyers = list(range(1, 101))     # æ‰€æœ‰100ä¸ªä¹°æ–¹ (20%æ¦‚ç‡ï¼ŒåŸæ¥æ˜¯1000)
        self.all_sellers = list(range(1, 101))    # æ‰€æœ‰100ä¸ªå–æ–¹

        print(f"ğŸ“Š æ•°æ®åˆ†å¸ƒé…ç½®:")
        print(f"  çƒ­é—¨ä¹°å–æ–¹: {len(self.hot_buyers)}x{len(self.hot_sellers)} = {len(self.hot_buyers)*len(self.hot_sellers)} ç»„åˆ")
        print(f"  å¸¸è§„ä¹°å–æ–¹: {len(self.regular_buyers)}x{len(self.regular_sellers)} = {len(self.regular_buyers)*len(self.regular_sellers)} ç»„åˆ")
        print(f"  å…¨éƒ¨ä¹°å–æ–¹: {len(self.all_buyers)}x{len(self.all_sellers)} = {len(self.all_buyers)*len(self.all_sellers)} ç»„åˆ")
    
    def setup_database(self):
        """è®¾ç½®æ•°æ®åº“ï¼šåˆ›å»ºè¡¨å’Œç´¢å¼•"""
        print("åˆ›å»ºæ•°æ®åº“è¡¨å’Œç´¢å¼•...")

        # ä¼˜å…ˆä½¿ç”¨åˆå¹¶çš„SQLæ–‡ä»¶ï¼ˆåŒ…å«è¡¨å’Œç´¢å¼•ï¼‰
        try:
            combined_sql = load_sql_file('schema/create_tables_with_indexes.sql')
            self.cur.execute(combined_sql)
            self.conn.commit()
            print("âœ“ æ•°æ®åº“è¡¨å’Œç´¢å¼•åˆ›å»ºå®Œæˆï¼ˆä½¿ç”¨åˆå¹¶æ–‡ä»¶ï¼‰")
        except FileNotFoundError:
            # å›é€€åˆ°åˆ†åˆ«åˆ›å»ºè¡¨å’Œç´¢å¼•
            print("  ä½¿ç”¨åˆ†ç¦»æ–‡ä»¶åˆ›å»ºè¡¨å’Œç´¢å¼•...")

            # åˆ›å»ºè¡¨
            create_tables_sql = load_sql_file('schema/create_tables.sql')
            self.cur.execute(create_tables_sql)
            self.conn.commit()
            print("  âœ“ æ•°æ®åº“è¡¨åˆ›å»ºå®Œæˆ")

            # è‡ªåŠ¨åˆ›å»ºç´¢å¼•
            try:
                self.create_indexes()
                print("  âœ“ ç´¢å¼•è‡ªåŠ¨åˆ›å»ºå®Œæˆ")
            except Exception as e:
                print(f"  âš ï¸ ç´¢å¼•åˆ›å»ºå¤±è´¥ï¼Œè¯·æ‰‹åŠ¨æ‰§è¡Œ: python tests/test_data_generator.py --create-indexes")
                print(f"     é”™è¯¯: {e}")
        except Exception as e:
            print(f"âŒ æ•°æ®åº“è®¾ç½®å¤±è´¥: {e}")
            raise
    
    def generate_blue_lines(self, total_lines: Optional[int] = None,
                           batch_id: Optional[str] = None,
                           resume_from: Optional[int] = None):
        """
        ç”Ÿæˆè“ç¥¨è¡Œæ•°æ®ï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼ å’Œå¹‚ç­‰æ€§ï¼‰

        Args:
            total_lines: æ€»è¡Œæ•°
            batch_id: æ‰¹æ¬¡IDï¼ˆé»˜è®¤ç”Ÿæˆæ—¶é—´æˆ³ï¼‰
            resume_from: ä»ç¬¬Næ¡å¼€å§‹ï¼ˆæ–­ç‚¹ç»­ä¼ ï¼Œè‡ªåŠ¨æ£€æµ‹ï¼‰
        """
        if total_lines is None:
            total_lines = self.total_lines

        # ç”Ÿæˆæ‰¹æ¬¡ID
        if batch_id is None:
            batch_id = f"batch_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

        print(f"å¼€å§‹ç”Ÿæˆ{total_lines:,}æ¡è“ç¥¨è¡Œæ•°æ®ï¼ˆæ‰¹æ¬¡ID: {batch_id}ï¼‰...")

        # è·å–å½“å‰æœ€å¤§ticket_idï¼Œç¡®ä¿ä¸å†²çª
        self.cur.execute("SELECT COALESCE(MAX(ticket_id), 0) FROM blue_lines")
        max_ticket_id = self.cur.fetchone()[0]

        # æ£€æŸ¥æ‰¹æ¬¡çŠ¶æ€
        resume_from = self._check_batch_status(batch_id, total_lines, resume_from)

        if resume_from and resume_from >= total_lines:
            print(f"æ‰¹æ¬¡ {batch_id} å·²å®Œæˆï¼Œæ— éœ€ç»§ç»­ç”Ÿæˆ")
            return batch_id
        insert_sql = """
            INSERT INTO blue_lines (
                ticket_id, tax_rate, buyer_id, seller_id,
                product_name, original_amount, remaining, batch_id
            ) VALUES %s
        """

        batch_data = []
        ticket_id = max_ticket_id + 1  # ä»æœ€å¤§IDå¼€å§‹ï¼Œé¿å…å†²çª

        # è°ƒæ•´èµ·å§‹ä½ç½®
        start_from = resume_from or 0
        actual_lines = total_lines - start_from
        
        with tqdm(total=actual_lines, initial=0) as pbar:
            for i in range(start_from, total_lines):
                # æ¯100è¡Œå±äºåŒä¸€å¼ ç¥¨æ®
                if i % 100 == 0:
                    ticket_id += 1

                # ç”Ÿæˆæ•°æ®ï¼ˆåŒ…å«batch_idï¼‰
                data = self._generate_single_blue_line(i, ticket_id, batch_id)
                batch_data.append(data)

                # æ‰¹é‡æ’å…¥
                if len(batch_data) >= self.batch_size:
                    execute_values(self.cur, insert_sql, batch_data)
                    self._update_batch_progress(batch_id, len(batch_data))
                    batch_data = []
                    pbar.update(self.batch_size)
            # æ’å…¥å‰©ä½™æ•°æ®
            if batch_data:
                execute_values(self.cur, insert_sql, batch_data)
                self._update_batch_progress(batch_id, len(batch_data))
                pbar.update(len(batch_data))

        self.conn.commit()

        # æ ‡è®°æ‰¹æ¬¡å®Œæˆ
        self._mark_batch_completed(batch_id)
        print(f"âœ“ {total_lines:,}æ¡è“ç¥¨è¡Œæ•°æ®ç”Ÿæˆå®Œæˆï¼ˆæ‰¹æ¬¡ID: {batch_id}ï¼‰")
        return batch_id
    
    def _generate_single_blue_line(self, index: int, ticket_id: int, batch_id: str):
        """
        ç”Ÿæˆå•æ¡è“ç¥¨è¡Œæ•°æ®
        å¤ç”¨ä¹‹å‰çš„æ•°æ®ç”Ÿæˆé€»è¾‘ï¼Œå¢åŠ batch_id
        """
        tax_rate = int(np.random.choice(self.tax_rates, p=self.tax_weights))  # è½¬æ¢ä¸ºPython int
        buyer_id, seller_id = self.generate_buyer_seller()
        remaining = self.generate_remaining_amount()
        original_amount = remaining * random.uniform(1.2, 2.0) if remaining > 0 else random.uniform(100, 1000)
        product_name = f"Product_{index % 1000}"

        return (
            ticket_id, tax_rate, buyer_id, seller_id,
            product_name, round(original_amount, 2), remaining, batch_id
        )
    
    def generate_remaining_amount(self):
        """
        ç”Ÿæˆæ›´è´´è¿‘çœŸå®åœºæ™¯çš„remainingé‡‘é¢åˆ†å¸ƒ
        å‡å°‘å®Œå…¨ç”¨å®Œçš„æ¯”ä¾‹ï¼Œå¢åŠ æœ‰æ•ˆå‰©ä½™é‡‘é¢
        """
        rand = random.random()
        if rand < 0.60:  # 60% remaining = 0 (ä»70%é™ä½)
            return 0
        elif rand < 0.75:  # 15% å°é¢ 1-100 (ä»12%å¢åŠ )
            return round(random.uniform(1, 100), 2)
        elif rand < 0.85:  # 10% ä¸­é¢ 100-500 (ä»6%å¢åŠ )
            return round(random.uniform(100, 500), 2)
        elif rand < 0.95:  # 10% å¤§é¢ 500-2000 (ä»3%å¤§å¹…å¢åŠ )
            return round(random.uniform(500, 2000), 2)
        else:  # 5% è¶…å¤§é¢ 2000-10000 (ä»1%å¢åŠ ä¸”é‡‘é¢èŒƒå›´æ‰©å¤§)
            return round(random.uniform(2000, 10000), 2)
    
    def generate_buyer_seller(self):
        """
        ç”Ÿæˆä¹°å–æ–¹ç»„åˆï¼ˆä¼˜åŒ–ç‰ˆï¼‰
        è°ƒæ•´æ¦‚ç‡åˆ†å¸ƒï¼Œå¢åŠ çƒ­é—¨ç»„åˆå¯†åº¦
        """
        rand = random.random()
        if rand < 0.40:  # 40% çƒ­é—¨ç»„åˆï¼ˆæé«˜ä»30%ï¼‰
            buyer = random.choice(self.hot_buyers)
            seller = random.choice(self.hot_sellers)
        elif rand < 0.80:  # 40% å¸¸è§„ç»„åˆï¼ˆä¿æŒ40%ï¼‰
            buyer = random.choice(self.regular_buyers)
            seller = random.choice(self.regular_sellers)
        else:  # 20% é•¿å°¾ç»„åˆï¼ˆä¿æŒ20%ï¼‰
            buyer = random.choice(self.all_buyers)
            seller = random.choice(self.all_sellers)
        return buyer, seller
    
    def create_indexes(self):
        """åˆ›å»ºç´¢å¼•ï¼ˆåŒ…æ‹¬éƒ¨åˆ†ç´¢å¼•ï¼‰"""
        print("\nåˆ›å»ºç´¢å¼•...")

        # ä»SQLæ–‡ä»¶åŠ è½½ç´¢å¼•è¯­å¥
        indexes_sql = load_sql_file('schema/create_indexes.sql')

        # æŒ‰åˆ†å·åˆ†å‰²å¤šä¸ªSQLè¯­å¥
        statements = [stmt.strip() for stmt in indexes_sql.split(';') if stmt.strip()]

        for stmt in statements:
            # è·³è¿‡æ³¨é‡Šè¡Œ
            if stmt.startswith('--') or not stmt.strip():
                continue

            if 'CREATE INDEX' in stmt.upper():
                # æå–ç´¢å¼•åï¼ˆç”¨äºæ˜¾ç¤ºè¿›åº¦ï¼‰
                try:
                    idx_name = stmt.split()[2] if len(stmt.split()) > 2 else 'unknown'
                    print(f"  åˆ›å»ºç´¢å¼• {idx_name}...")
                    start_time = time.time()
                    self.cur.execute(stmt)
                    self.conn.commit()
                    elapsed = time.time() - start_time
                    print(f"    âœ“ å®Œæˆ (è€—æ—¶: {elapsed:.2f}ç§’)")
                except Exception as e:
                    print(f"    âŒ åˆ›å»ºå¤±è´¥: {e}")
            elif stmt.strip().upper().startswith('ANALYZE'):
                print("  æ›´æ–°ç»Ÿè®¡ä¿¡æ¯...")
                try:
                    self.cur.execute(stmt)
                    self.conn.commit()
                    print("    âœ“ ç»Ÿè®¡ä¿¡æ¯æ›´æ–°å®Œæˆ")
                except Exception as e:
                    print(f"    âŒ ç»Ÿè®¡æ›´æ–°å¤±è´¥: {e}")

        print("âœ“ ç´¢å¼•åˆ›å»ºå®Œæˆ")
    
    def generate_negative_invoices_objects(self, scenario="mixed", count: Optional[int] = None) -> List[NegativeInvoice]:
        """
        ç”Ÿæˆè´Ÿæ•°å‘ç¥¨å¯¹è±¡ï¼ˆä¾›æ ¸å¿ƒæ¨¡å—ä½¿ç”¨ï¼‰

        Args:
            scenario: åœºæ™¯ç±»å‹
            count: ç”Ÿæˆæ•°é‡ï¼ˆå¯é€‰ï¼Œè¦†ç›–åœºæ™¯é»˜è®¤æ•°é‡ï¼‰

        Returns:
            List[NegativeInvoice]: è´Ÿæ•°å‘ç¥¨å¯¹è±¡åˆ—è¡¨
        """
        invoice_data = self.generate_negative_invoices_data(scenario, count)

        return [
            NegativeInvoice(
                invoice_id=data['id'],
                amount=Decimal(str(data['amount'])),
                tax_rate=data['tax_rate'],
                buyer_id=data['buyer_id'],
                seller_id=data['seller_id'],
                priority=data.get('priority', 0)
            )
            for data in invoice_data
        ]
    
    def generate_negative_invoices_data(self, scenario="mixed", count: Optional[int] = None) -> List[Dict]:
        """
        ç”Ÿæˆè´Ÿæ•°å‘ç¥¨æµ‹è¯•æ•°æ®ï¼ˆåŸå§‹å­—å…¸æ ¼å¼ï¼‰
        ä¿ç•™è¿™ä¸ªæ–¹æ³•ç”¨äºå‘åå…¼å®¹

        Args:
            scenario: åœºæ™¯ç±»å‹ (small/mixed/stress/custom)
            count: ç”Ÿæˆæ•°é‡ï¼ˆå¯é€‰ï¼Œè¦†ç›–åœºæ™¯é»˜è®¤æ•°é‡ï¼‰
        """
        negative_data = []

        if scenario == "small":
            # å°é¢åœºæ™¯ï¼šé»˜è®¤200æ¡ï¼Œ10-100å…ƒ
            total_count = count if count is not None else 200
            for i in range(total_count):
                amount = random.uniform(10, 100)
                tax_rate = random.choice([13, 6])
                buyer_id = random.choice(self.hot_buyers)
                seller_id = random.choice(self.hot_sellers)
                negative_data.append({
                    'id': i + 1,
                    'amount': round(amount, 2),
                    'tax_rate': tax_rate,
                    'buyer_id': buyer_id,
                    'seller_id': seller_id
                })

        elif scenario == "mixed":
            # æ··åˆåœºæ™¯ï¼šä¸åŒé‡‘é¢èŒƒå›´
            if count is not None:
                # å¦‚æœæŒ‡å®šäº†æ•°é‡ï¼ŒæŒ‰æ¯”ä¾‹åˆ†é…
                ranges = [
                    (int(count * 0.5), 10, 100),    # 50% 10-100å…ƒ
                    (int(count * 0.3), 100, 500),   # 30% 100-500å…ƒ
                    (int(count * 0.15), 500, 1000), # 15% 500-1000å…ƒ
                    (int(count * 0.05), 1000, 5000),# 5% 1000-5000å…ƒ
                ]
            else:
                # é»˜è®¤é…ç½®
                ranges = [
                    (50, 10, 100),    # 50æ¡ 10-100å…ƒ
                    (30, 100, 500),   # 30æ¡ 100-500å…ƒ
                    (15, 500, 1000),  # 15æ¡ 500-1000å…ƒ
                    (5, 1000, 5000),  # 5æ¡ 1000-5000å…ƒ
                ]

            id_counter = 1
            for count_in_range, min_amt, max_amt in ranges:
                for _ in range(count_in_range):
                    amount = random.uniform(min_amt, max_amt)
                    tax_rate = int(np.random.choice(self.tax_rates, p=self.tax_weights))
                    buyer_id, seller_id = self.generate_buyer_seller()
                    negative_data.append({
                        'id': id_counter,
                        'amount': round(amount, 2),
                        'tax_rate': tax_rate,
                        'buyer_id': buyer_id,
                        'seller_id': seller_id
                    })
                    id_counter += 1

        elif scenario == "stress":
            # å‹åŠ›æµ‹è¯•ï¼šé»˜è®¤1000æ¡éšæœº
            total_count = count if count is not None else 1000
            for i in range(total_count):
                amount = random.uniform(10, 5000)
                tax_rate = int(np.random.choice(self.tax_rates, p=self.tax_weights))
                buyer_id, seller_id = self.generate_buyer_seller()
                negative_data.append({
                    'id': i + 1,
                    'amount': round(amount, 2),
                    'tax_rate': tax_rate,
                    'buyer_id': buyer_id,
                    'seller_id': seller_id
                })

        elif scenario == "custom":
            # è‡ªå®šä¹‰åœºæ™¯ï¼šå®Œå…¨éšæœº
            total_count = count if count is not None else 100
            for i in range(total_count):
                amount = random.uniform(1, 10000)
                tax_rate = int(np.random.choice(self.tax_rates, p=self.tax_weights))
                buyer_id, seller_id = self.generate_buyer_seller()
                negative_data.append({
                    'id': i + 1,
                    'amount': round(amount, 2),
                    'tax_rate': tax_rate,
                    'buyer_id': buyer_id,
                    'seller_id': seller_id
                })

        # æŒ‰é‡‘é¢é™åºæ’åºï¼ˆå¤§é¢ä¼˜å…ˆï¼‰
        negative_data.sort(key=lambda x: x['amount'], reverse=True)

        return negative_data
    
    def _print_statistics(self):
        """æ‰“å°æ•°æ®ç»Ÿè®¡ä¿¡æ¯"""
        print("\næ•°æ®åˆ†å¸ƒç»Ÿè®¡ï¼š")

        # ä»SQLæ–‡ä»¶åŠ è½½ç»Ÿè®¡æŸ¥è¯¢
        stats_sql = load_sql_file('test/stats_queries.sql')

        # æŒ‰åˆ†å·åˆ†å‰²å¤šä¸ªæŸ¥è¯¢ï¼Œå»é™¤æ³¨é‡Šè¡Œ
        queries = []
        current_query = []

        for line in stats_sql.split('\n'):
            line = line.strip()
            if line.startswith('--') or not line:
                continue
            current_query.append(line)
            if line.endswith(';'):
                queries.append(' '.join(current_query))
                current_query = []

        # æ‰§è¡Œç¬¬ä¸€ä¸ªæŸ¥è¯¢ï¼šä½™é¢åˆ†å¸ƒ
        if len(queries) >= 1:
            self.cur.execute(queries[0])
            print("\nRemainingåˆ†å¸ƒï¼š")
            for row in self.cur.fetchall():
                print(f"  {row[0]}: {row[1]:,} ({row[2]}%)")

        # æ‰§è¡Œç¬¬äºŒä¸ªæŸ¥è¯¢ï¼šç¨ç‡åˆ†å¸ƒ
        if len(queries) >= 2:
            self.cur.execute(queries[1])
            print("\nç¨ç‡åˆ†å¸ƒï¼š")
            for row in self.cur.fetchall():
                print(f"  {row[0]}%: {row[1]:,} ({row[2]}%)")

        # æ‰§è¡Œç¬¬ä¸‰ä¸ªæŸ¥è¯¢ï¼šæ´»è·ƒæ•°æ®ç»Ÿè®¡
        if len(queries) >= 3:
            self.cur.execute(queries[2])
            row = self.cur.fetchone()
            print(f"\næ´»è·ƒæ•°æ®ï¼š{row[0]:,} / {row[1]:,} ({row[2]}%)")

    # ========== æ‰¹æ¬¡ç®¡ç†æ–¹æ³• ==========

    def _check_batch_status(self, batch_id: str, total_lines: int, resume_from: Optional[int] = None) -> Optional[int]:
        """
        æ£€æŸ¥æ‰¹æ¬¡çŠ¶æ€ï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ 

        Args:
            batch_id: æ‰¹æ¬¡ID
            total_lines: æ€»è¡Œæ•°
            resume_from: æŒ‡å®šçš„ç»­ä¼ ä½ç½®

        Returns:
            int: ç»­ä¼ ä½ç½®ï¼ˆå¦‚æœéœ€è¦ç»­ä¼ ï¼‰
        """
        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨æ‰¹æ¬¡è®°å½•
        self.cur.execute("""
            SELECT total_lines, inserted_lines, status, start_time
            FROM batch_metadata WHERE batch_id = %s
        """, (batch_id,))

        result = self.cur.fetchone()

        if result:
            existing_total, existing_inserted, status, start_time = result
            print(f"å‘ç°æ‰¹æ¬¡ {batch_id}ï¼š")
            print(f"  çŠ¶æ€: {status}")
            print(f"  å¼€å§‹æ—¶é—´: {start_time}")
            print(f"  è¿›åº¦: {existing_inserted:,} / {existing_total:,}")

            if status == 'completed':
                print(f"  æ‰¹æ¬¡å·²å®Œæˆï¼Œæ— éœ€ç»§ç»­")
                return existing_inserted

            if status == 'running':
                # æ£€æŸ¥å®é™…æ•°æ®åº“ä¸­çš„è®°å½•æ•°
                self.cur.execute("""
                    SELECT COUNT(*) FROM blue_lines WHERE batch_id = %s
                """, (batch_id,))
                actual_count = self.cur.fetchone()[0]

                if actual_count < existing_inserted:
                    # æ•°æ®ä¸ä¸€è‡´ï¼Œä»å®é™…æ•°é‡å¼€å§‹
                    print(f"  æ•°æ®ä¸ä¸€è‡´ï¼Œä»å®é™…æ•°é‡ {actual_count:,} ç»§ç»­")
                    self._update_batch_metadata(batch_id, total_lines, actual_count, 'running')
                    return actual_count
                else:
                    print(f"  ä»ä¸Šæ¬¡ä¸­æ–­ä½ç½® {existing_inserted:,} ç»§ç»­")
                    return existing_inserted
        else:
            # åˆ›å»ºæ–°çš„æ‰¹æ¬¡è®°å½•
            self._create_batch_metadata(batch_id, total_lines)
            print(f"åˆ›å»ºæ–°æ‰¹æ¬¡ {batch_id}")

        return resume_from

    def _create_batch_metadata(self, batch_id: str, total_lines: int):
        """åˆ›å»ºæ‰¹æ¬¡å…ƒæ•°æ®è®°å½•"""
        self.cur.execute("""
            INSERT INTO batch_metadata (batch_id, total_lines, inserted_lines, status)
            VALUES (%s, %s, 0, 'running')
        """, (batch_id, total_lines))
        self.conn.commit()

    def _update_batch_progress(self, batch_id: str, increment: int):
        """æ›´æ–°æ‰¹æ¬¡è¿›åº¦"""
        self.cur.execute("""
            UPDATE batch_metadata
            SET inserted_lines = inserted_lines + %s,
                resumed_at = CURRENT_TIMESTAMP
            WHERE batch_id = %s
        """, (increment, batch_id))

    def _update_batch_metadata(self, batch_id: str, total_lines: int, inserted_lines: int, status: str):
        """æ›´æ–°æ‰¹æ¬¡å…ƒæ•°æ®"""
        self.cur.execute("""
            UPDATE batch_metadata
            SET total_lines = %s, inserted_lines = %s, status = %s,
                resumed_at = CURRENT_TIMESTAMP
            WHERE batch_id = %s
        """, (total_lines, inserted_lines, status, batch_id))
        self.conn.commit()

    def _mark_batch_completed(self, batch_id: str):
        """æ ‡è®°æ‰¹æ¬¡å®Œæˆ"""
        self.cur.execute("""
            UPDATE batch_metadata
            SET status = 'completed', end_time = CURRENT_TIMESTAMP
            WHERE batch_id = %s
        """, (batch_id,))
        self.conn.commit()

    def list_batches(self):
        """åˆ—å‡ºæ‰€æœ‰æ‰¹æ¬¡ä¿¡æ¯"""
        self.cur.execute("""
            SELECT batch_id, table_name, total_lines, inserted_lines, status,
                   start_time, end_time,
                   CASE
                       WHEN total_lines > 0 THEN ROUND(inserted_lines * 100.0 / total_lines, 2)
                       ELSE 0
                   END as progress_percent
            FROM batch_metadata
            ORDER BY start_time DESC
        """)

        results = self.cur.fetchall()
        if not results:
            print("æš‚æ— æ‰¹æ¬¡è®°å½•")
            return

        print("\næ‰¹æ¬¡åˆ—è¡¨ï¼š")
        print("=" * 100)
        print(f"{'æ‰¹æ¬¡ID':<20} {'è¡¨å':<12} {'æ€»æ•°':<10} {'å·²æ’å…¥':<10} {'è¿›åº¦':<8} {'çŠ¶æ€':<10} {'å¼€å§‹æ—¶é—´':<19} {'ç»“æŸæ—¶é—´'}")
        print("-" * 100)

        for row in results:
            batch_id, table_name, total, inserted, status, start_time, end_time, progress = row
            end_str = end_time.strftime('%Y-%m-%d %H:%M:%S') if end_time else '-'
            print(f"{batch_id:<20} {table_name:<12} {total:<10,} {inserted:<10,} {progress:<7.1f}% {status:<10} {start_time.strftime('%Y-%m-%d %H:%M:%S')} {end_str}")

    def clear_batch(self, batch_id: str):
        """æ¸…ç†æŒ‡å®šæ‰¹æ¬¡çš„æ•°æ®"""
        # æ£€æŸ¥æ‰¹æ¬¡æ˜¯å¦å­˜åœ¨
        self.cur.execute("SELECT COUNT(*) FROM batch_metadata WHERE batch_id = %s", (batch_id,))
        if self.cur.fetchone()[0] == 0:
            print(f"æ‰¹æ¬¡ {batch_id} ä¸å­˜åœ¨")
            return

        # åˆ é™¤æ•°æ®
        self.cur.execute("DELETE FROM blue_lines WHERE batch_id = %s", (batch_id,))
        deleted_count = self.cur.rowcount

        # åˆ é™¤å…ƒæ•°æ®
        self.cur.execute("DELETE FROM batch_metadata WHERE batch_id = %s", (batch_id,))

        self.conn.commit()
        print(f"âœ“ å·²æ¸…ç†æ‰¹æ¬¡ {batch_id}ï¼Œåˆ é™¤ {deleted_count:,} æ¡æ•°æ®")

    def reset_test_data(self):
        """é‡ç½®æµ‹è¯•æ•°æ®ï¼ˆç”¨äºé‡å¤æµ‹è¯•ï¼‰"""
        print("é‡ç½®æµ‹è¯•æ•°æ®...")

        # ä»SQLæ–‡ä»¶åŠ è½½é‡ç½®è¯­å¥
        reset_sql = load_sql_file('test/reset_data.sql')

        # æŒ‰åˆ†å·åˆ†å‰²å¹¶æ‰§è¡Œæ¯ä¸ªè¯­å¥
        statements = [stmt.strip() for stmt in reset_sql.split(';') if stmt.strip() and not stmt.strip().startswith('--')]

        for stmt in statements:
            if stmt.upper().startswith('SELECT'):
                # å¯¹äºéªŒè¯æŸ¥è¯¢ï¼Œæ˜¾ç¤ºç»“æœ
                self.cur.execute(stmt)
                result = self.cur.fetchone()
                if result:
                    total, restored, inconsistent, avg_remaining, avg_original = result
                    print(f"  æ•°æ®éªŒè¯: æ€»è¡Œæ•°={total:,}, å·²æ¢å¤={restored:,}, å¼‚å¸¸={inconsistent}, å¹³å‡ä½™é¢={avg_remaining}, å¹³å‡åŸå§‹={avg_original}")
            else:
                self.cur.execute(stmt)

        self.conn.commit()
        print("âœ“ æµ‹è¯•æ•°æ®å·²é‡ç½®")

    def force_reset_to_fresh_state(self):
        """å¼ºåˆ¶é‡ç½®æ‰€æœ‰æ•°æ®åˆ°å®Œå…¨å¯ç”¨çŠ¶æ€ï¼ˆç”¨äºæ€§èƒ½æµ‹è¯•ï¼‰"""
        print("å¼ºåˆ¶é‡ç½®æ•°æ®åˆ°å®Œå…¨å¯ç”¨çŠ¶æ€...")

        # ä»SQLæ–‡ä»¶åŠ è½½å¼ºåˆ¶é‡ç½®è¯­å¥
        force_reset_sql = load_sql_file('test/force_reset_data.sql')

        # æŒ‰åˆ†å·åˆ†å‰²å¹¶æ‰§è¡Œæ¯ä¸ªè¯­å¥
        statements = [stmt.strip() for stmt in force_reset_sql.split(';') if stmt.strip() and not stmt.strip().startswith('--')]

        for stmt in statements:
            if stmt.upper().startswith('SELECT'):
                # å¯¹äºéªŒè¯æŸ¥è¯¢ï¼Œæ˜¾ç¤ºç»“æœ
                self.cur.execute(stmt)
                result = self.cur.fetchone()
                if result:
                    total, available, exhausted, avg_remaining, avg_original, availability = result
                    print(f"  æ•°æ®éªŒè¯: æ€»è¡Œæ•°={total:,}, å®Œå…¨å¯ç”¨={available:,}, å·²ç”¨å®Œ={exhausted:,}")
                    print(f"  å¹³å‡ä½™é¢={avg_remaining}, å¹³å‡åŸå§‹={avg_original}, å¯ç”¨æ€§={availability}%")
            else:
                self.cur.execute(stmt)

        self.conn.commit()
        print("âœ“ æ•°æ®å·²å¼ºåˆ¶é‡ç½®åˆ°å®Œå…¨å¯ç”¨çŠ¶æ€")

    def create_data_snapshot(self, snapshot_name: str = None):
        """åˆ›å»ºæ•°æ®å¿«ç…§ï¼ˆä¿å­˜ remaining å€¼ï¼‰"""
        if snapshot_name is None:
            snapshot_name = f"snapshot_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

        print(f"åˆ›å»ºæ•°æ®å¿«ç…§: {snapshot_name}")

        # åˆ›å»ºå¿«ç…§è¡¨ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        self.cur.execute("""
            CREATE TABLE IF NOT EXISTS data_snapshots (
                snapshot_name VARCHAR(100),
                line_id BIGINT,
                remaining_value DECIMAL(15,2),
                snapshot_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                PRIMARY KEY (snapshot_name, line_id)
            )
        """)

        # åˆ é™¤åŒåå¿«ç…§ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        self.cur.execute("DELETE FROM data_snapshots WHERE snapshot_name = %s", (snapshot_name,))

        # ä¿å­˜å½“å‰ remaining å€¼
        self.cur.execute("""
            INSERT INTO data_snapshots (snapshot_name, line_id, remaining_value)
            SELECT %s, line_id, remaining FROM blue_lines
        """, (snapshot_name,))

        affected_rows = self.cur.rowcount
        self.conn.commit()
        print(f"âœ“ å¿«ç…§å·²åˆ›å»ºï¼Œä¿å­˜äº† {affected_rows:,} æ¡è®°å½•")
        return snapshot_name

    def restore_from_snapshot(self, snapshot_name: str):
        """ä»å¿«ç…§æ¢å¤æ•°æ®"""
        print(f"ä»å¿«ç…§æ¢å¤æ•°æ®: {snapshot_name}")

        # æ£€æŸ¥å¿«ç…§æ˜¯å¦å­˜åœ¨
        self.cur.execute("SELECT COUNT(*) FROM data_snapshots WHERE snapshot_name = %s", (snapshot_name,))
        snapshot_count = self.cur.fetchone()[0]

        if snapshot_count == 0:
            raise ValueError(f"å¿«ç…§ä¸å­˜åœ¨: {snapshot_name}")

        # æ¸…ç©ºåŒ¹é…è®°å½•
        self.cur.execute("TRUNCATE TABLE match_records CASCADE")

        # ä»å¿«ç…§æ¢å¤ remaining å€¼
        self.cur.execute("""
            UPDATE blue_lines
            SET remaining = ds.remaining_value,
                last_update = CURRENT_TIMESTAMP
            FROM data_snapshots ds
            WHERE blue_lines.line_id = ds.line_id
              AND ds.snapshot_name = %s
        """, (snapshot_name,))

        updated_rows = self.cur.rowcount
        self.conn.commit()
        print(f"âœ“ æ•°æ®å·²æ¢å¤ï¼Œæ›´æ–°äº† {updated_rows:,} æ¡è®°å½•")

        # éªŒè¯æ¢å¤çŠ¶æ€
        self._verify_data_consistency()

    def list_snapshots(self):
        """åˆ—å‡ºæ‰€æœ‰å¯ç”¨å¿«ç…§"""
        self.cur.execute("""
            SELECT snapshot_name, COUNT(*) as record_count,
                   MIN(snapshot_time) as created_time
            FROM data_snapshots
            GROUP BY snapshot_name
            ORDER BY created_time DESC
        """)

        results = self.cur.fetchall()
        if not results:
            print("æš‚æ— æ•°æ®å¿«ç…§")
            return

        print("\nå¯ç”¨æ•°æ®å¿«ç…§ï¼š")
        print("=" * 60)
        print(f"{'å¿«ç…§åç§°':<25} {'è®°å½•æ•°':<10} {'åˆ›å»ºæ—¶é—´'}")
        print("-" * 60)

        for snapshot_name, count, created_time in results:
            print(f"{snapshot_name:<25} {count:<10,} {created_time.strftime('%Y-%m-%d %H:%M:%S')}")

    def delete_snapshot(self, snapshot_name: str):
        """åˆ é™¤æŒ‡å®šå¿«ç…§"""
        self.cur.execute("DELETE FROM data_snapshots WHERE snapshot_name = %s", (snapshot_name,))
        deleted_count = self.cur.rowcount
        self.conn.commit()

        if deleted_count > 0:
            print(f"âœ“ å·²åˆ é™¤å¿«ç…§ {snapshot_name}ï¼Œæ¸…ç†äº† {deleted_count:,} æ¡è®°å½•")
        else:
            print(f"å¿«ç…§ {snapshot_name} ä¸å­˜åœ¨")

    def _verify_data_consistency(self):
        """éªŒè¯æ•°æ®ä¸€è‡´æ€§"""
        self.cur.execute("""
            SELECT
                COUNT(*) as total_lines,
                COUNT(CASE WHEN remaining < 0 THEN 1 END) as negative_remaining,
                COUNT(CASE WHEN remaining > original_amount THEN 1 END) as excess_remaining,
                ROUND(AVG(remaining), 2) as avg_remaining,
                ROUND(SUM(remaining), 2) as total_remaining
            FROM blue_lines
        """)

        result = self.cur.fetchone()
        if result:
            total, negative, excess, avg_remaining, total_remaining = result
            print(f"  æ•°æ®éªŒè¯: æ€»è¡Œæ•°={total:,}, è´Ÿæ•°ä½™é¢={negative}, è¶…é¢ä½™é¢={excess}")
            print(f"  å¹³å‡ä½™é¢={avg_remaining}, æ€»ä½™é¢={total_remaining:,}")

            if negative > 0 or excess > 0:
                print(f"  âš ï¸  å‘ç°æ•°æ®å¼‚å¸¸: è´Ÿæ•°ä½™é¢={negative}, è¶…é¢ä½™é¢={excess}")

    def get_data_utilization_stats(self):
        """è·å–æ•°æ®åˆ©ç”¨ç‡ç»Ÿè®¡"""
        self.cur.execute("""
            SELECT
                COUNT(*) as total_lines,
                COUNT(CASE WHEN remaining = 0 THEN 1 END) as exhausted_lines,
                COUNT(CASE WHEN remaining = original_amount THEN 1 END) as unused_lines,
                COUNT(CASE WHEN remaining > 0 AND remaining < original_amount THEN 1 END) as partial_used_lines,
                ROUND(AVG(remaining / original_amount * 100), 2) as avg_utilization_percent,
                ROUND(SUM(remaining), 2) as total_remaining,
                ROUND(SUM(original_amount), 2) as total_original
            FROM blue_lines
            WHERE original_amount > 0
        """)

        result = self.cur.fetchone()
        if result:
            total, exhausted, unused, partial, avg_util, total_remaining, total_original = result

            # å¤„ç† None å€¼
            total = total or 0
            exhausted = exhausted or 0
            unused = unused or 0
            partial = partial or 0
            avg_util = avg_util or 0
            total_remaining = total_remaining or 0
            total_original = total_original or 0

            utilization_rate = (1 - total_remaining / total_original) * 100 if total_original > 0 else 0

            print(f"\nğŸ“Š æ•°æ®åˆ©ç”¨ç‡ç»Ÿè®¡:")
            print(f"  æ€»è¡Œæ•°: {total:,}")
            if total > 0:
                print(f"  å·²ç”¨å®Œ: {exhausted:,} ({exhausted/total*100:.1f}%)")
                print(f"  æœªä½¿ç”¨: {unused:,} ({unused/total*100:.1f}%)")
                print(f"  éƒ¨åˆ†ä½¿ç”¨: {partial:,} ({partial/total*100:.1f}%)")
            else:
                print(f"  å·²ç”¨å®Œ: {exhausted:,} (0.0%)")
                print(f"  æœªä½¿ç”¨: {unused:,} (0.0%)")
                print(f"  éƒ¨åˆ†ä½¿ç”¨: {partial:,} (0.0%)")
            print(f"  å¹³å‡åˆ©ç”¨ç‡: {avg_util:.1f}%")
            print(f"  æ€»ä½“åˆ©ç”¨ç‡: {utilization_rate:.1f}%")
            print(f"  å‰©ä½™é‡‘é¢: {total_remaining:,} / {total_original:,}")

            return {
                'total_lines': total,
                'exhausted_lines': exhausted,
                'unused_lines': unused,
                'partial_used_lines': partial,
                'avg_utilization_percent': avg_util,
                'total_utilization_percent': utilization_rate,
                'total_remaining': total_remaining,
                'total_original': total_original
            }
    
    def close(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        self.cur.close()
        self.conn.close()


def run_generator(args):
    """
    æ ¹æ®å‚æ•°è¿è¡Œæ•°æ®ç”Ÿæˆå™¨
    """
    from config.config import get_db_config

    # è·å–é…ç½®
    db_config = get_db_config(args.env)
    # test_config = get_test_config()  # æš‚æ—¶ä¿ç•™ï¼Œå¯èƒ½ç”¨äºæœªæ¥æ‰©å±•

    # è‡ªå®šä¹‰é…ç½®è¦†ç›–
    config_overrides = {}
    if args.total_lines:
        config_overrides['total_lines'] = args.total_lines
    if args.batch_size:
        config_overrides['batch_size'] = args.batch_size

    # åˆå§‹åŒ–ç”Ÿæˆå™¨
    generator = TestDataGenerator(db_config, config_overrides)

    try:
        print(f"ä½¿ç”¨ç¯å¢ƒ: {args.env}")
        print(f"æ•°æ®åº“: {db_config['database']}")

        # 1. è®¾ç½®æ•°æ®åº“ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if args.setup_db:
            print("\n=== è®¾ç½®æ•°æ®åº“ ===")
            generator.setup_database()

        # 2. ç”Ÿæˆè“ç¥¨è¡Œæ•°æ®ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if args.generate_blue_lines:
            print("\n=== ç”Ÿæˆè“ç¥¨è¡Œæ•°æ® ===")
            total_lines = args.total_lines or generator.total_lines
            batch_id = args.batch_id
            resume_from = args.resume_from
            result_batch_id = generator.generate_blue_lines(total_lines, batch_id, resume_from)
            print(f"æ‰¹æ¬¡ID: {result_batch_id}")

        # æ‰¹æ¬¡ç®¡ç†æ“ä½œ
        if args.list_batches:
            print("\n=== æ‰¹æ¬¡åˆ—è¡¨ ===")
            generator.list_batches()

        if args.clear_batch:
            print(f"\n=== æ¸…ç†æ‰¹æ¬¡ {args.clear_batch} ===")
            generator.clear_batch(args.clear_batch)

        # æ•°æ®å¿«ç…§ç®¡ç†æ“ä½œ
        if args.create_snapshot:
            print(f"\n=== åˆ›å»ºæ•°æ®å¿«ç…§ ===")
            snapshot_name = generator.create_data_snapshot(args.snapshot_name)
            print(f"å¿«ç…§åˆ›å»ºå®Œæˆ: {snapshot_name}")

        if args.list_snapshots:
            print("\n=== å¿«ç…§åˆ—è¡¨ ===")
            generator.list_snapshots()

        if args.restore_snapshot:
            print(f"\n=== æ¢å¤å¿«ç…§ {args.restore_snapshot} ===")
            generator.restore_from_snapshot(args.restore_snapshot)

        if args.delete_snapshot:
            print(f"\n=== åˆ é™¤å¿«ç…§ {args.delete_snapshot} ===")
            generator.delete_snapshot(args.delete_snapshot)

        if args.data_stats:
            print("\n=== æ•°æ®åˆ©ç”¨ç‡ç»Ÿè®¡ ===")
            generator.get_data_utilization_stats()

        # 3. åˆ›å»ºç´¢å¼•ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if args.create_indexes:
            print("\n=== åˆ›å»ºç´¢å¼• ===")
            generator.create_indexes()

        # 4. ç”Ÿæˆç¤ºä¾‹è´Ÿæ•°å‘ç¥¨ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if args.generate_negatives:
            print("\n=== ç”Ÿæˆè´Ÿæ•°å‘ç¥¨ ===")
            scenario = args.scenario or 'mixed'
            count = args.negative_count

            test_invoices = generator.generate_negative_invoices_objects(scenario, count)
            print(f"\nç”Ÿæˆäº† {len(test_invoices)} æ¡æµ‹è¯•è´Ÿæ•°å‘ç¥¨ (åœºæ™¯: {scenario})")

            if args.show_samples:
                print("å‰5æ¡ï¼š")
                for inv in test_invoices[:5]:
                    print(f"  ID:{inv.invoice_id}, é‡‘é¢:{inv.amount}, "
                          f"ç¨ç‡:{inv.tax_rate}%, ä¹°æ–¹:{inv.buyer_id}, å–æ–¹:{inv.seller_id}")

        # 5. é‡ç½®æµ‹è¯•æ•°æ®ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if args.reset_data:
            print("\n=== é‡ç½®æµ‹è¯•æ•°æ® ===")
            generator.reset_test_data()

        if args.force_reset:
            print("\n=== å¼ºåˆ¶é‡ç½®åˆ°å®Œå…¨å¯ç”¨çŠ¶æ€ ===")
            generator.force_reset_to_fresh_state()

        print("\nâœ“ æ“ä½œå®Œæˆ")

    except Exception as e:
        print(f"\nâŒ æ‰§è¡Œå¤±è´¥: {e}")
        raise
    finally:
        generator.close()


def parse_args():
    """
    è§£æå‘½ä»¤è¡Œå‚æ•°
    """
    parser = argparse.ArgumentParser(
        description='è´Ÿæ•°å‘ç¥¨åŒ¹é…ç³»ç»Ÿæµ‹è¯•æ•°æ®ç”Ÿæˆå™¨',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:

åŸºç¡€æ“ä½œ:
  # å®Œæ•´åˆå§‹åŒ–ï¼ˆé¦–æ¬¡ä½¿ç”¨ï¼‰
  python test_data_generator.py --setup-db --generate-blue-lines --total-lines 1000000 --create-indexes

  # åªè®¾ç½®æ•°æ®åº“
  python test_data_generator.py --setup-db

  # ç”Ÿæˆ1åƒä¸‡æ¡æ•°æ®ï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰
  python test_data_generator.py --generate-blue-lines --total-lines 10000000 --batch-id prod_001

æ‰¹æ¬¡ç®¡ç†:
  # æŸ¥çœ‹æ‰€æœ‰æ‰¹æ¬¡çŠ¶æ€
  python test_data_generator.py --list-batches

  # ç»§ç»­æœªå®Œæˆçš„æ‰¹æ¬¡ï¼ˆè‡ªåŠ¨æ£€æµ‹æ–­ç‚¹ï¼‰
  python test_data_generator.py --generate-blue-lines --batch-id prod_001

  # æ¸…ç†ç‰¹å®šæ‰¹æ¬¡æ•°æ®
  python test_data_generator.py --clear-batch prod_001

æµ‹è¯•æ•°æ®:
  # ç”Ÿæˆ500æ¡æ··åˆåœºæ™¯è´Ÿæ•°å‘ç¥¨
  python test_data_generator.py --generate-negatives --scenario mixed --negative-count 500

  # é‡ç½®æµ‹è¯•æ•°æ®
  python test_data_generator.py --reset-data

ç¯å¢ƒé…ç½®:
  # ä½¿ç”¨å¼€å‘ç¯å¢ƒ
  python test_data_generator.py --generate-blue-lines --env dev --total-lines 100000

æ€§èƒ½ä¼˜åŒ–:
  # è°ƒæ•´æ‰¹æ¬¡å¤§å°ä»¥ä¼˜åŒ–æ€§èƒ½
  python test_data_generator.py --generate-blue-lines --total-lines 1000000 --batch-size 50000
        """
    )

    # ç¯å¢ƒé…ç½®
    parser.add_argument('--env', default='test', choices=['test', 'dev', 'prod'],
                       help='æ•°æ®åº“ç¯å¢ƒ (é»˜è®¤: test)')

    # æ“ä½œé€‰é¡¹
    parser.add_argument('--all', action='store_true',
                       help='æ‰§è¡Œæ‰€æœ‰æ“ä½œï¼ˆè®¾ç½®æ•°æ®åº“ã€ç”Ÿæˆæ•°æ®ã€åˆ›å»ºç´¢å¼•ã€ç”Ÿæˆè´Ÿæ•°å‘ç¥¨ï¼‰')
    parser.add_argument('--setup-db', action='store_true',
                       help='è®¾ç½®æ•°æ®åº“ï¼ˆåˆ›å»ºè¡¨ï¼‰')
    parser.add_argument('--generate-blue-lines', action='store_true',
                       help='ç”Ÿæˆè“ç¥¨è¡Œæ•°æ®')
    parser.add_argument('--create-indexes', action='store_true',
                       help='åˆ›å»ºç´¢å¼•')
    parser.add_argument('--generate-negatives', action='store_true',
                       help='ç”Ÿæˆè´Ÿæ•°å‘ç¥¨æµ‹è¯•æ•°æ®')
    parser.add_argument('--reset-data', action='store_true',
                       help='é‡ç½®æµ‹è¯•æ•°æ®')
    parser.add_argument('--force-reset', action='store_true',
                       help='å¼ºåˆ¶é‡ç½®æ•°æ®åˆ°å®Œå…¨å¯ç”¨çŠ¶æ€ï¼ˆç”¨äºæ€§èƒ½æµ‹è¯•ï¼‰')

    # æ•°æ®ç”Ÿæˆå‚æ•°
    parser.add_argument('--total-lines', type=int,
                       help='è“ç¥¨è¡Œæ€»æ•°ï¼ˆé»˜è®¤: 10,000,000ï¼‰')
    parser.add_argument('--batch-size', type=int,
                       help='æ‰¹é‡æ’å…¥å¤§å°ï¼ˆé»˜è®¤: 10,000ï¼‰')

    # è´Ÿæ•°å‘ç¥¨å‚æ•°
    parser.add_argument('--scenario', choices=['small', 'mixed', 'stress', 'custom'],
                       help='è´Ÿæ•°å‘ç¥¨åœºæ™¯ç±»å‹ï¼ˆé»˜è®¤: mixedï¼‰')
    parser.add_argument('--negative-count', type=int,
                       help='è´Ÿæ•°å‘ç¥¨æ•°é‡ï¼ˆè¦†ç›–åœºæ™¯é»˜è®¤å€¼ï¼‰')
    parser.add_argument('--show-samples', action='store_true',
                       help='æ˜¾ç¤ºç”Ÿæˆçš„è´Ÿæ•°å‘ç¥¨æ ·ä¾‹')

    # æ‰¹æ¬¡ç®¡ç†å‚æ•°
    parser.add_argument('--batch-id', type=str,
                       help='æ‰¹æ¬¡IDï¼ˆç”¨äºæ–­ç‚¹ç»­ä¼ å’Œæ•°æ®è¿½è¸ªï¼‰')
    parser.add_argument('--resume-from', type=int,
                       help='ä»æŒ‡å®šä½ç½®ç»§ç»­ç”Ÿæˆï¼ˆé€šå¸¸ç”±ç³»ç»Ÿè‡ªåŠ¨æ£€æµ‹ï¼‰')
    parser.add_argument('--list-batches', action='store_true',
                       help='åˆ—å‡ºæ‰€æœ‰æ‰¹æ¬¡ä¿¡æ¯')
    parser.add_argument('--clear-batch', type=str,
                       help='æ¸…ç†æŒ‡å®šæ‰¹æ¬¡çš„æ•°æ®')

    # æ•°æ®å¿«ç…§ç®¡ç†å‚æ•°
    parser.add_argument('--create-snapshot', action='store_true',
                       help='åˆ›å»ºæ•°æ®å¿«ç…§ï¼ˆä¿å­˜å½“å‰ remaining å€¼ï¼‰')
    parser.add_argument('--snapshot-name', type=str,
                       help='å¿«ç…§åç§°ï¼ˆå¯é€‰ï¼Œé»˜è®¤ç”Ÿæˆæ—¶é—´æˆ³ï¼‰')
    parser.add_argument('--list-snapshots', action='store_true',
                       help='åˆ—å‡ºæ‰€æœ‰å¯ç”¨å¿«ç…§')
    parser.add_argument('--restore-snapshot', type=str,
                       help='ä»æŒ‡å®šå¿«ç…§æ¢å¤æ•°æ®')
    parser.add_argument('--delete-snapshot', type=str,
                       help='åˆ é™¤æŒ‡å®šå¿«ç…§')
    parser.add_argument('--data-stats', action='store_true',
                       help='æ˜¾ç¤ºæ•°æ®åˆ©ç”¨ç‡ç»Ÿè®¡')

    args = parser.parse_args()

    # å¦‚æœä½¿ç”¨ --allï¼Œåˆ™å¯ç”¨æ‰€æœ‰æ“ä½œ
    if args.all:
        args.setup_db = True
        args.generate_blue_lines = True
        args.create_indexes = True
        args.generate_negatives = True
        args.show_samples = True

    # å¦‚æœæ²¡æœ‰æŒ‡å®šä»»ä½•æ“ä½œï¼Œé»˜è®¤åªç”Ÿæˆæ•°æ®ï¼ˆä¸åˆ é™¤è¡¨ï¼‰
    if not any([
        args.setup_db, args.generate_blue_lines, args.create_indexes,
        args.generate_negatives, args.reset_data, args.force_reset, args.list_batches, args.clear_batch,
        args.create_snapshot, args.list_snapshots, args.restore_snapshot,
        args.delete_snapshot, args.data_stats
    ]):
        # åªç”Ÿæˆæ•°æ®ï¼Œä¸æ‰§è¡Œç ´åæ€§æ“ä½œ
        args.generate_blue_lines = True
        args.create_indexes = True  # ç¡®ä¿ç´¢å¼•å­˜åœ¨
        # æ³¨æ„ï¼šä¸è‡ªåŠ¨è®¾ç½® setup_db = Trueï¼Œé¿å…æ„å¤–åˆ é™¤è¡¨
        args.generate_negatives = True
        args.show_samples = True

    return args


# ========== å¸¸ç”¨æ“ä½œè¯´æ˜ ==========
"""
åƒä¸‡çº§æ•°æ®ç”Ÿæˆæœ€ä½³å®è·µï¼š

1. é¦–æ¬¡è®¾ç½®ï¼š
   python test_data_generator.py --setup-db

2. å¤§æ•°æ®é‡ç”Ÿæˆï¼ˆæ¨èä½¿ç”¨batch_idï¼‰ï¼š
   python test_data_generator.py --generate-blue-lines --total-lines 10000000 --batch-id prod_001

3. æ–­ç‚¹ç»­ä¼ ï¼ˆå¦‚æœä¸­æ–­ï¼‰ï¼š
   python test_data_generator.py --generate-blue-lines --batch-id prod_001
   # ç³»ç»Ÿè‡ªåŠ¨æ£€æµ‹è¿›åº¦å¹¶ç»­ä¼ 

4. ç›‘æ§è¿›åº¦ï¼š
   python test_data_generator.py --list-batches

5. æ¸…ç†æ•°æ®ï¼š
   python test_data_generator.py --clear-batch prod_001

6. æ€§èƒ½è°ƒä¼˜ï¼š
   - è°ƒæ•´ --batch-size å‚æ•°
   - ä½¿ç”¨é€‚å½“çš„ batch_id å‘½å
   - å®šæœŸæŸ¥çœ‹æ‰¹æ¬¡çŠ¶æ€

æ³¨æ„äº‹é¡¹ï¼š
- é‡å¤æ‰§è¡Œç›¸åŒå‘½ä»¤ä¼šå¯¼è‡´æ•°æ®ç´¯åŠ 
- ä½¿ç”¨ä¸åŒçš„batch_idé¿å…æ•°æ®æ··ä¹±
- å¤§æ•°æ®é‡æ“ä½œå»ºè®®åœ¨ä½å³°æœŸè¿›è¡Œ
"""


# ç‹¬ç«‹è¿è¡Œæ—¶çš„åˆå§‹åŒ–è„šæœ¬
if __name__ == "__main__":
    args = parse_args()
    run_generator(args)
    