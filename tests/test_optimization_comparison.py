#!/usr/bin/env python3
"""
ä¼˜åŒ–æ•ˆæœå¯¹æ¯”æµ‹è¯•

å¯¹æ¯”ç´¢å¼•ä¼˜åŒ–å‰åçš„æ€§èƒ½å·®å¼‚ï¼ŒéªŒè¯ï¼š
1. æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½æå‡
2. æ•´ä½“åŒ¹é…æ€§èƒ½æ”¹è¿›
3. è¯¦ç»†æ€§èƒ½ç›‘æ§æ•°æ®

ä½¿ç”¨ç°æœ‰çš„æµ‹è¯•æ•°æ®è¿›è¡Œå¯¹æ¯”æµ‹è¯•ã€‚
"""

import sys
import os
import time
from datetime import datetime
from typing import List, Dict

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from core.matching_engine import GreedyMatchingEngine, NegativeInvoice
from core.db_manager import DatabaseManager, CandidateProvider
from core.performance_monitor import get_performance_timer, reset_performance_timer
from config.config import get_db_config
from tests.test_data_generator import TestDataGenerator
import psycopg2


class OptimizationComparison:
    """ä¼˜åŒ–æ•ˆæœå¯¹æ¯”æµ‹è¯•"""

    def __init__(self):
        self.db_config = get_db_config('test')
        self.db_manager = DatabaseManager(self.db_config)
        self.engine = GreedyMatchingEngine()
        self.candidate_provider = CandidateProvider(self.db_manager)
        self.data_generator = TestDataGenerator(self.db_config)

    def test_database_query_performance(self):
        """æµ‹è¯•æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½"""
        print("=== æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½æµ‹è¯• ===")

        conn = psycopg2.connect(**self.db_config)
        cur = conn.cursor()

        # æµ‹è¯•åœºæ™¯ï¼šæŸ¥è¯¢çƒ­é—¨ç»„åˆ
        test_cases = [
            (13, 1, 1),  # çƒ­é—¨ç»„åˆ
            (13, 5, 6),  # çƒ­é—¨ç»„åˆ
            (6, 2, 2),   # ä¸­ç­‰ç»„åˆ
            (3, 50, 50), # é•¿å°¾ç»„åˆ
        ]

        results = []

        for tax_rate, buyer_id, seller_id in test_cases:
            print(f"\\næµ‹è¯•ç»„åˆ: ç¨ç‡{tax_rate}%, ä¹°æ–¹{buyer_id}, å–æ–¹{seller_id}")

            # æ‰§è¡ŒæŸ¥è¯¢å¹¶è®°å½•æ—¶é—´
            start_time = time.time()
            cur.execute("""
                EXPLAIN (ANALYZE, BUFFERS, FORMAT JSON)
                SELECT line_id, remaining, tax_rate, buyer_id, seller_id
                FROM blue_lines
                WHERE tax_rate = %s
                  AND buyer_id = %s
                  AND seller_id = %s
                  AND remaining > 0
                ORDER BY remaining ASC
                LIMIT 10000
            """, (tax_rate, buyer_id, seller_id))

            explain_result = cur.fetchone()[0][0]
            execution_time = time.time() - start_time

            # è§£ææ‰§è¡Œè®¡åˆ’
            plan = explain_result['Plan']
            actual_time = plan['Actual Total Time']
            index_used = 'Index Scan' in plan.get('Node Type', '')

            print(f"  æ‰§è¡Œæ—¶é—´: {actual_time:.2f}ms")
            print(f"  ä½¿ç”¨ç´¢å¼•: {'æ˜¯' if index_used else 'å¦'}")
            print(f"  æ‰«ææ–¹å¼: {plan.get('Node Type', 'æœªçŸ¥')}")

            results.append({
                'combination': f"{tax_rate}_{buyer_id}_{seller_id}",
                'execution_time_ms': actual_time,
                'index_used': index_used,
                'scan_type': plan.get('Node Type', 'æœªçŸ¥')
            })

        cur.close()
        conn.close()

        # è¾“å‡ºæ±‡æ€»
        print(f"\\n=== æŸ¥è¯¢æ€§èƒ½æ±‡æ€» ===")
        total_queries = len(results)
        index_queries = sum(1 for r in results if r['index_used'])
        avg_time = sum(r['execution_time_ms'] for r in results) / len(results)

        print(f"æ€»æŸ¥è¯¢æ•°: {total_queries}")
        print(f"ä½¿ç”¨ç´¢å¼•: {index_queries}/{total_queries} ({index_queries/total_queries:.1%})")
        print(f"å¹³å‡æŸ¥è¯¢æ—¶é—´: {avg_time:.2f}ms")

        return results

    def test_matching_performance_with_monitoring(self):
        """æµ‹è¯•åŒ¹é…æ€§èƒ½ï¼ˆå¸¦è¯¦ç»†ç›‘æ§ï¼‰"""
        print("\\n=== åŒ¹é…æ€§èƒ½æµ‹è¯•ï¼ˆè¯¦ç»†ç›‘æ§ï¼‰ ===")

        # é‡ç½®æ€§èƒ½è®¡æ—¶å™¨
        reset_performance_timer()
        timer = get_performance_timer()

        # ç”Ÿæˆæµ‹è¯•è´Ÿæ•°å‘ç¥¨
        negatives = self.data_generator.generate_negative_invoices_objects(
            scenario="mixed", count=100
        )

        print(f"ç”Ÿæˆ {len(negatives)} ä¸ªæµ‹è¯•è´Ÿæ•°å‘ç¥¨")

        # æ‰§è¡ŒåŒ¹é…æµ‹è¯•
        start_time = time.time()

        with timer.measure("total_matching_process"):
            results = self.engine.match_batch(
                negatives,
                self.candidate_provider,
                sort_strategy="amount_desc",
                enable_monitoring=True
            )

        total_time = time.time() - start_time

        # åˆ†æç»“æœ
        success_count = sum(1 for r in results if r.success)
        success_rate = success_count / len(results)
        total_matched = sum(r.total_matched for r in results)
        fragments = sum(r.fragments_created for r in results)

        print(f"\\nåŒ¹é…ç»“æœ:")
        print(f"  æˆåŠŸåŒ¹é…: {success_count}/{len(results)} ({success_rate:.1%})")
        print(f"  æ€»åŒ¹é…é‡‘é¢: {total_matched}")
        print(f"  äº§ç”Ÿç¢ç‰‡: {fragments}")
        print(f"  æ€»è€—æ—¶: {total_time:.3f}ç§’")

        # è¯¦ç»†æ€§èƒ½åˆ†æ
        print(f"\\n=== è¯¦ç»†æ€§èƒ½åˆ†æ ===")
        timer.print_summary()

        # ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
        performance_report = timer.get_performance_report(self.db_manager)

        return {
            'matching_results': {
                'total_invoices': len(results),
                'success_count': success_count,
                'success_rate': success_rate,
                'total_matched_amount': float(total_matched),
                'fragments_created': fragments,
                'total_time_seconds': total_time
            },
            'performance_report': performance_report
        }

    def compare_with_baseline(self):
        """ä¸åŸºå‡†æ€§èƒ½å¯¹æ¯”"""
        print("\\n=== æ€§èƒ½å¯¹æ¯” ===")

        # åŸºå‡†æ•°æ®ï¼ˆä¼˜åŒ–å‰çš„é¢„æœŸæ€§èƒ½ï¼‰
        baseline = {
            'query_time_ms': 1250,  # ä¹‹å‰æµ‹è¯•çš„å…¨è¡¨æ‰«ææ—¶é—´
            'p99_response_ms': 11000,  # ä¹‹å‰çš„P99å“åº”æ—¶é—´
            'success_rate': 0.70,  # ä¹‹å‰çš„åŒ¹é…ç‡
        }

        # å½“å‰æ€§èƒ½ï¼ˆä¼˜åŒ–åï¼‰
        query_results = self.test_database_query_performance()
        matching_results = self.test_matching_performance_with_monitoring()

        current = {
            'query_time_ms': sum(r['execution_time_ms'] for r in query_results) / len(query_results),
            'success_rate': matching_results['matching_results']['success_rate'],
            'total_time_seconds': matching_results['matching_results']['total_time_seconds']
        }

        # è®¡ç®—æ”¹è¿›å¹…åº¦
        query_improvement = baseline['query_time_ms'] / current['query_time_ms']
        success_improvement = current['success_rate'] / baseline['success_rate']

        print(f"\\nğŸ“Š æ€§èƒ½æ”¹è¿›å¯¹æ¯”:")
        print(f"{'æŒ‡æ ‡':<20} {'ä¼˜åŒ–å‰':<15} {'ä¼˜åŒ–å':<15} {'æ”¹è¿›å¹…åº¦':<15}")
        print("-" * 70)
        print(f"{'å¹³å‡æŸ¥è¯¢æ—¶é—´':<20} {baseline['query_time_ms']:<15.1f} {current['query_time_ms']:<15.1f} {query_improvement:<15.1f}x")
        print(f"{'åŒ¹é…æˆåŠŸç‡':<20} {baseline['success_rate']:<15.1%} {current['success_rate']:<15.1%} {success_improvement:<15.1f}x")

        # ç»“è®º
        print(f"\\nğŸ¯ ä¼˜åŒ–æ•ˆæœ:")
        if query_improvement > 10:
            print(f"  âœ… æŸ¥è¯¢æ€§èƒ½æå‡æ˜¾è‘—: {query_improvement:.1f}å€")
        elif query_improvement > 2:
            print(f"  âœ… æŸ¥è¯¢æ€§èƒ½æœ‰æ‰€æå‡: {query_improvement:.1f}å€")
        else:
            print(f"  âš ï¸ æŸ¥è¯¢æ€§èƒ½æå‡æœ‰é™: {query_improvement:.1f}å€")

        if current['success_rate'] > 0.93:
            print(f"  âœ… åŒ¹é…ç‡è¾¾åˆ°ç›®æ ‡: {current['success_rate']:.1%} > 93%")
        elif current['success_rate'] > baseline['success_rate']:
            print(f"  âœ… åŒ¹é…ç‡æœ‰æ‰€æå‡: {current['success_rate']:.1%}")
        else:
            print(f"  âš ï¸ åŒ¹é…ç‡éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–: {current['success_rate']:.1%}")

        return {
            'baseline': baseline,
            'current': current,
            'improvements': {
                'query_improvement': query_improvement,
                'success_improvement': success_improvement
            }
        }

    def generate_optimization_report(self):
        """ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š"""
        print("\\n=== ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š ===")

        # è¿è¡Œå®Œæ•´æµ‹è¯•
        comparison_results = self.compare_with_baseline()

        # ç”ŸæˆæŠ¥å‘Š
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_path = f"docs/optimization_report_{timestamp}.md"

        report_content = f"""
# è´Ÿæ•°å‘ç¥¨åŒ¹é…ç³»ç»Ÿä¼˜åŒ–æŠ¥å‘Š

## ä¼˜åŒ–æ¦‚è¿°
- **ä¼˜åŒ–æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **ä¸»è¦ä¼˜åŒ–**: åˆ›å»ºéƒ¨åˆ†ç´¢å¼•ï¼Œé›†æˆæ€§èƒ½ç›‘æ§
- **æµ‹è¯•ç¯å¢ƒ**: PostgreSQL 17.6, 4æ ¸8çº¿ç¨‹, 16GBå†…å­˜

## ä¼˜åŒ–æªæ–½

### 1. ç´¢å¼•ä¼˜åŒ–
åˆ›å»ºäº†ä»¥ä¸‹å…³é”®ç´¢å¼•ï¼š
- `idx_active`: éƒ¨åˆ†ç´¢å¼• (tax_rate, buyer_id, seller_id) WHERE remaining > 0
- `idx_ticket`: ç¥¨æ®ç´¢å¼•
- `idx_remaining`: ä½™é¢ç´¢å¼•
- `idx_batch`: æ‰¹æ¬¡ç´¢å¼•
- `idx_batch_status`: æ‰¹æ¬¡çŠ¶æ€å¤åˆç´¢å¼•

### 2. æ€§èƒ½ç›‘æ§
é›†æˆäº†è¯¦ç»†çš„æ€§èƒ½ç›‘æ§ç³»ç»Ÿï¼š
- æ•°æ®åº“è¿æ¥æ—¶é—´ç›‘æ§
- SQLæŸ¥è¯¢æ‰§è¡Œæ—¶é—´
- æ•°æ®è½¬æ¢æ—¶é—´
- äº‹åŠ¡å¤„ç†æ—¶é—´

## æ€§èƒ½æ”¹è¿›ç»“æœ

| æŒ‡æ ‡ | ä¼˜åŒ–å‰ | ä¼˜åŒ–å | æ”¹è¿›å¹…åº¦ |
|------|--------|--------|----------|
| å¹³å‡æŸ¥è¯¢æ—¶é—´ | {comparison_results['baseline']['query_time_ms']:.1f}ms | {comparison_results['current']['query_time_ms']:.1f}ms | {comparison_results['improvements']['query_improvement']:.1f}x |
| åŒ¹é…æˆåŠŸç‡ | {comparison_results['baseline']['success_rate']:.1%} | {comparison_results['current']['success_rate']:.1%} | {comparison_results['improvements']['success_improvement']:.1f}x |

## æŠ€æœ¯åˆ†æ

### ç´¢å¼•æ•ˆæœéªŒè¯
é€šè¿‡EXPLAIN ANALYZEéªŒè¯ï¼ŒæŸ¥è¯¢å·²ä»å…¨è¡¨æ‰«æï¼ˆSeq Scanï¼‰æ”¹ä¸ºç´¢å¼•æ‰«æï¼ˆIndex Scanï¼‰ï¼ŒæŸ¥è¯¢æ€§èƒ½æå‡{comparison_results['improvements']['query_improvement']:.1f}å€ã€‚

### ç›‘æ§æ•°æ®
è¯¦ç»†çš„æ€§èƒ½ç›‘æ§æ˜¾ç¤ºå„ä¸ªæ­¥éª¤çš„è€—æ—¶åˆ†å¸ƒï¼Œä¸ºåç»­ä¼˜åŒ–æä¾›äº†æ•°æ®æ”¯æ’‘ã€‚

## ç»“è®º

{'âœ… ä¼˜åŒ–æ˜¾è‘—æœ‰æ•ˆ' if comparison_results['improvements']['query_improvement'] > 10 else 'âš ï¸ ä¼˜åŒ–æ•ˆæœæœ‰é™'}

æ ¸å¿ƒçš„éƒ¨åˆ†ç´¢å¼•ä¼˜åŒ–å·²æˆåŠŸå®æ–½ï¼ŒæŸ¥è¯¢æ€§èƒ½å¾—åˆ°æ˜¾è‘—æå‡ã€‚å»ºè®®åœ¨æ­¤åŸºç¡€ä¸Šè¿›ä¸€æ­¥ä¼˜åŒ–æ•°æ®åˆ†å¸ƒå¯†åº¦ã€‚

## ä¸‹ä¸€æ­¥å»ºè®®

1. ä¼˜åŒ–æ•°æ®ç”Ÿæˆç­–ç•¥ï¼Œæé«˜æ•°æ®å¯†åº¦
2. å®æ–½æŸ¥è¯¢ç¼“å­˜æœºåˆ¶
3. è€ƒè™‘è¯»å†™åˆ†ç¦»æ¶æ„
4. ç›‘æ§ç”Ÿäº§ç¯å¢ƒæ€§èƒ½æŒ‡æ ‡
"""

        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report_content)

        print(f"âœ… ä¼˜åŒ–æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
        return report_path

    def close(self):
        """æ¸…ç†èµ„æº"""
        self.data_generator.close()


def main():
    """ä¸»å‡½æ•°"""
    print("=== è´Ÿæ•°å‘ç¥¨åŒ¹é…ç³»ç»Ÿä¼˜åŒ–æ•ˆæœå¯¹æ¯” ===\\n")

    comparison = OptimizationComparison()

    try:
        # è¿è¡Œå¯¹æ¯”æµ‹è¯•å¹¶ç”ŸæˆæŠ¥å‘Š
        report_path = comparison.generate_optimization_report()

        print(f"\\nğŸ‰ ä¼˜åŒ–å¯¹æ¯”æµ‹è¯•å®Œæˆï¼")
        print(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Š: {report_path}")

    except Exception as e:
        print(f"\\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    finally:
        comparison.close()


if __name__ == "__main__":
    main()